---
title: "[λ”¥λ¬λ‹] μ„Ήμ…3-1: Pre-Trained CNN(1)"
author: sujungeee
date: 2023-08-02 17:01:00 +0800
categories: [μΈκ³µμ§€λ¥, λ”¥λ¬λ‹]
tags: [μΈκ³µμ§€λ¥, AI, λ”¥λ¬λ‹, λ¨Έμ‹ λ¬λ‹, TensorFlow, CNN, μ΄λ―Έμ§€ μ¶”μ¶]
render_with_liquid: false

---



β€» λ³Έ ν¬μ¤ν…μ€ μΈν”„λ° "μ°¨λ‰ λ²νΈν μΈμ‹ ν”„λ΅μ νΈμ™€ TensorFlowλ΅ λ°°μ°λ” λ”¥λ¬λ‹ μμƒμΈμ‹ μ¬μΈμ›" μ„ μ°Έκ³ ν•μ—¬ μ‘μ„±ν•μ€μµλ‹λ‹¤.



#### β…  tf.train.CheckpointManager API λ¥Ό μ΄μ©ν•΄μ„ νλΌλ―Έν„° μ €μ¥ν•κ³  λ¶λ¬μ¤κΈ°

- νλΌλ―Έν„°λ¥Ό μ €μ¥ν•λ” λ²•

  - tf.train.Checkpoint ν΄λμ¤μ μΈμ κ°’: μ €μ¥ν•κ³ μ ν•λ” tf.keras.Model μΈμ¤ν„΄μ¤μ™€ μ „μ—­ λ°λ³µ νμλ¥Ό μ§€μ •ν•μ—¬ μ„ μ–Έ

    : ckpt= tf.train.Checkpoint(step= tf.Variable(0), model= CNN_model)

  - tf.train.CheckpointManager μ μΈμ κ°’: ckpt, μ¤‘κ°„ νλΌλ―Έν„°λ¥Ό μ €μ¥ν•  ν΄λ” κ²½λ΅(directory), max_to_keep(κ°€μ¥ μµκ·Όμ— λ‡ κ°μ νμΌμ„ μ €μ¥ν•΄μ„ λ‚¨κ²¨λ†“μ„ μ§€λ¥Ό μ§€μ •)

    : ckpt_manager= tf.train.CheckpointManager(ckpt, directory= SAVER_DIR, max_to_keep= 5)

  - tf.train.CheckpointManager μ save λ©”μ†λ“μ μΈμ κ°’: νλΌλ―Έν„°λ¥Ό μ €μ¥ν•κ³ μ ν•λ” μ‹μ μ— ν•΄λ‹Ή μ‹μ μ μ „μ—­ λ°λ³µ νμ

    : ckpt_manager.save(checkpoint_numver= ckpt.step)

  - tf.train.Checkpoint μ μ „μ—­ λ°λ³µ νμ κ°’(ckpt.step or tf.Variable(0)) μ„ λ§¤ λ°λ³µλ§λ‹¤ 1μ”© μ¦κ°€

    : ckpt.step.assign_add(1)

- νλΌλ―Έν„°λ¥Ό λ¶λ¬μ¤λ” λ²•

  : λ¶λ¬μ¤λ©΄ β†’ 1. μ΄μ–΄μ„ ν•™μµ 2. λ°”λ΅ μ¶”λ΅ 

  - tf.train.latest_checkpoint μ μΈμ κ°’: νλΌλ―Έν„°κ°€ μ €μ¥λ ν΄λ” κ²½λ΅

    : latest_ckpt= tf.train.latest_checkpoint(SAVER_DIR)

    β†’ κ°€μ¥ μµκ·Όμ μ²΄ν¬ ν¬μΈνΈ νμΌμ κ²½λ΅(full path) λ¥Ό κ°€μ Έμ΄

  - μ„ μ–Έν• tf.train.CheckpointManager μ restore ν•¨μμ μΈμ κ°’: λ¶λ¬μ¬ μ²΄ν¬ ν¬μΈνΈ νμΌμ κ²½λ΅

    : ckpt.restore(latest_ckpt)



#### β…  ν…μ„λ³΄λ“(TensorBoard) λ¥Ό μ΄μ©ν•΄μ„ ν•™μµ κ³Όμ • μ‹κ°ν™”(Visualization) ν•κΈ°

- tf.summary λ΅κ·Έμ ν•νƒ

  : TensorBoard μ λ€ν‘μ μΈ 3 κ°€μ§€ ν•νƒμ API

  - tf.summary.scalar: scalar κ°’ ν•νƒμ λ΅κ·Έ μ €μ¥
  - tf.summary.histogram: histogram ν•νƒμ λ΅κ·Έ μ €μ¥
  - tf.summary.image: μ΄λ―Έμ§€ ν•νƒμ λ΅κ·Έ μ €μ¥

- TensorBoard λ¥Ό μ‚¬μ©ν•κΈ° μ„ν• 2κ°€μ§€ κ³Όμ •

  1. ν…μ„λ³΄λ“ λ΅κ·Έλ¥Ό μ €μ¥

  - μΈμ κ°’μΌλ΅ ν…μ„λ³΄λ“ λ΅κ·Έ νμΌμ„ μ €μ¥ν•  κ²½λ΅λ¥Ό μ§€μ •ν•΄μ„ File Writer μƒμ„±

    : summary_writer= tf.summary.create_file_writer(β€™./tensorboard_logβ€™)

  - μ”μ•½ μ •λ³΄λ¥Ό λ‚¨κΈ°κ³  μ‹¶μ€ κ°’μ„ Writer Scope λ‚΄μ—μ„ tf.summary.* API λ΅ μ¶”κ°€

    : with summary_writer.as_default():

    tf.summary.scalar(β€™lossβ€™, loss, step= optimizer.iterations)

  1. ν…μ„λ³΄λ“ μ‹¤ν–‰ λ°©λ²•

  - ν…μ„λ³΄λ“λ¥Ό μ‹¤ν–‰ν•λ” ν„°λ―Έλ„ λ…λ Ήμ–΄

    : tensorboard --logdir= path\to\log-directory

  - μ›ΉλΈλΌμ°μ €μ—μ„ ν…μ„λ³΄λ“μ μ‹¤ν–‰ κ²°κ³Όλ¥Ό ν™•μΈ

    : localhost:6006



#### β…  ResNet

- ν•µμ‹¬ μ•„μ΄λ””μ–΄: Degradation Problem μ„ ν•΄κ²°ν•κΈ° μ„ν• residual block architecture λ¥Ό μ μ•ν•κ³  μ΄μ μ •λ‹Ήμ„±μ„ μ‹¤ν—μ μΌλ΅ μ…μ¦ν•¨

- Degradation Problem

  : λ” κΉμ€ λ μ΄μ–΄μΌμλ΅ νλΌλ―Έν„° μκ°€ μ¦κ°€ν•κΈ° λ•λ¬Έμ— optimization μ΄ μ λ€λ΅ μν–‰λμ§€ μ•λ” λ¬Έμ 

  - λ μ΄μ–΄κ°€ κΉμ–΄μ§μλ΅ μ„±λ¥μ΄ λ–¨μ–΄μ§€λ” ν„μƒμ΄ κ΄€μ°°λ¨
  - νΈλ μ΄λ‹ μ—λ¬μ— λ€ν•΄μ„λ„ λ°μƒν•λ” ν„μƒμ΄μ–΄μ„ μ¤λ²„ν”Όν… λ¬Έμ κ°€ μ•„λ‹

- Residual Block Architecture(Identity Mapping)

  : input μ shortcut μ„ μ¶”κ°€ν•΄μ„ μµμ ν™”ν•  νλΌλ―Έν„°μ μλ¥Ό μ¤„μ„

  β‡’ κΉμ€ λ μ΄μ–΄μ„μ—λ„ λ¶κµ¬ν•κ³  μµμ ν™”ν•  νλΌλ―Έν„° μκ°€ μ¤„κΈ° λ•λ¬Έμ— μ„±λ¥μ΄ κ°μ„ λ¨

- ResNet μ μ•„μ΄λ””μ–΄

  - λμ–΄λ‚ μ°¨μ›λ§νΌ zero-padding μ„ μ μ©

  - W_s κ³±μ…μ„ ν†µν•΄ μ°¨μ› λ³€κ²½μ„ μν–‰ν• μ΄ν›„μ— λ§μ…μ„ μν–‰

    : y= F(x, {W_i}) + W_s*x

  β‡’ error rate κ°€ λΉ„μ·ν•κΈ° λ•λ¬Έμ— μ—°μ‚°λ‰μ΄ μ μ€ zero-padding λ°©λ²•μ„ κ¶μ¥

> Deeper Bottleneck Architectures
>
> : 1X1 Convolution μ„ μ΄μ©ν•΄μ„ μ—°μ‚°λ‰μ„ μ¤„μΈ λ””μμΈ

- ResNet μ μμ

  - Identity Mapping μ„ μ¶”κ°€ν• Shortcut μ„ μ¶”κ°€ν•¨μΌλ΅μ¨ Layer Depth λ¥Ό νκΈ°μ μΌλ΅ λλ¦¬λ” μ°½μμ μΈ μ•„μ΄λ””μ–΄λ¥Ό μ μ•

  - μ΄ν›„ 100-depth μ΄μƒμ κΉμ€ CNN λ¨λΈ μ‹λ€λ¥Ό μ—¬λ” μ‹μ΄κ°€ λ¨

  - Faster R-CNN μ Backbone μ„ VGG-16 μ—μ„ ResNet μΌλ΅ λ°”κΎΈκ² λ¨(?)

  - 1202 depth λ” 110 depth μ™€ λΉ„κµν•μ€μ„ λ• μ¤νλ ¤ error rate κ°€ λ†’κ² λ‚μ΄

    β‡’ μ¤λ²„ν”Όν…μ λ¬Έμ κ°€ μ•„λ‹κΉ ν•λ” open problem μ„ λ‚¨κΉ€



#### β…  EfficientNet

- CNN μ μ„±λ¥μ„ λ†’μΌ μ μλ” μ”μ†

  : κ° μ”μ†λ“¤μ scaling μ— μ§‘μ¤‘

  - baseline CNN λ¨λΈμ„ μ„ νƒ
  - CNN μ Width(ν•„ν„°μ κ°μ) λ¥Ό λλ¦Ό
  - CNN μ Depth(λ μ΄μ–΄μ κ°μ) λ¥Ό λλ¦Ό
  - CNN μ μΈν’‹ μ΄λ―Έμ§€μ Resolution(ν¬κΈ°) μ„ λλ¦Ό

- Compound Scaling Method

  : Width, Depth, Resolution μ μ„Έ μ”μ†λ¥Ό μ΅°ν™”λ΅­κ² scaling

  - μ„Έ depth, width, resolution μ„ μ μ ν μ„¤μ •ν•κ³ , π™ λ¥Ό ν• λ‹Ήν•λ©΄ π™ μ— λΉ„λ΅€ν• CNN λ¨λΈμ„ λ§λ“¤ μ μμ
  - π™ μ΄ μ‘μΌλ©΄β†’ EfficientNet-B0: μ„±λ¥μ€ λ–¨μ–΄μ§€μ§€λ§ μ†λ„λ” ν–¥μƒ
  - π™ μ΄ ν¬λ©΄β†’ EfficientNet-B7: μ„±λ¥μ€ ν–¥μƒλμ§€λ§ μ†λ„λ” λ–¨μ–΄μ§
  - κ°κ°μ μ”μ†λ¥Ό μ„¤μ •ν•λ” κ²ƒλ³΄λ‹¤ μ„Έ μ”μ†λ¥Ό compound ν•μ—¬ μ„¤μ •ν•λ©΄ μ²μ²ν saturation μ΄ μ΄λ¤„μ§

- Model Architecture & Experiments

  : μ‹¤μ  λ¬Έμ μ— μ μ©ν•  λ• κΈ°μ΅΄ λ¨λΈμ— λΉ„ν•΄ ν›¨μ”¬ ν¨μ¨μ 

  - μ†λ„ ν–¥μƒ
  - μ •ν™•λ„ ν–¥μƒ

- EfficientNet μ μμ

  - μ μ€ μμ νλΌλ―Έν„°λ¥Ό κ°€μ§€λ©΄μ„ μΆ‹μ€ μ„±λ¥μ„ λ³΄μ—¬μ£Όλ” State-of-the-art(SOTA) CNN λ¨λΈμ„ μ μ•
  - Depth, Width, Resolution μ„ μ΅°ν™”λ΅­κ² λλ¦¬λ” Compound Scaling Method λ¥Ό μ μ•
